(window.webpackJsonp=window.webpackJsonp||[]).push([[174],{501:function(t,s,a){"use strict";a.r(s);var n=a(7),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"介绍"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#介绍"}},[t._v("#")]),t._v(" 介绍")]),t._v(" "),s("p",[t._v("现阶段，应用于搜索引擎和自然语言处理的中文分词库五花八门，使用方式各不统一，虽然有适配于Lucene和Elasticsearch的插件，但是我们想在多个库之间选择更换时，依旧有学习时间。")]),t._v(" "),s("p",[t._v("Hutool针对常见中文分词库做了统一接口封装，即定义一套规范，隔离各个库的差异，做到一段代码，随意更换。")]),t._v(" "),s("p",[t._v("Hutool现在封装的引擎有：")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://github.com/NLPchina/ansj_seg",target:"_blank",rel:"noopener noreferrer"}},[t._v("Ansj"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/hankcs/HanLP",target:"_blank",rel:"noopener noreferrer"}},[t._v("HanLP"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/yozhao/IKAnalyzer",target:"_blank",rel:"noopener noreferrer"}},[t._v("IKAnalyzer"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://gitee.com/lionsoul/jcseg",target:"_blank",rel:"noopener noreferrer"}},[t._v("Jcseg"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/huaban/jieba-analysis",target:"_blank",rel:"noopener noreferrer"}},[t._v("Jieba"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/chenlb/mmseg4j-core",target:"_blank",rel:"noopener noreferrer"}},[t._v("mmseg4j"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/ysc/word",target:"_blank",rel:"noopener noreferrer"}},[t._v("Word"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/chenlb/mmseg4j-core",target:"_blank",rel:"noopener noreferrer"}},[t._v("Smartcn"),s("OutboundLink")],1)])]),t._v(" "),s("blockquote",[s("p",[t._v("注意\n此工具和模块从Hutool-4.4.0开始支持。")])]),t._v(" "),s("h2",{attrs:{id:"原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#原理"}},[t._v("#")]),t._v(" 原理")]),t._v(" "),s("p",[t._v("类似于Java日志门面的思想，Hutool将分词引擎的渲染抽象为三个概念：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("TokenizerEngine")]),t._v(" 分词引擎，用于封装分词库对象")]),t._v(" "),s("li",[s("code",[t._v("Result")]),t._v(" 分词结果接口定义，用于抽象对文本分词的结果，实现了Iterator和Iterable接口，用于遍历分词")]),t._v(" "),s("li",[s("code",[t._v("Word")]),t._v(" 表示分词中的一个词，既分词后的单词，可以获取单词文本、起始位置和结束位置等信息")])]),t._v(" "),s("p",[t._v("通过实现这三个接口，用户便可抛开分词库的差异，实现多文本分词。")]),t._v(" "),s("p",[t._v("Hutool同时会通过"),s("code",[t._v("TokenizerFactory")]),s("strong",[t._v("根据用户引入的分词库的jar来自动选择用哪个库实现分词")]),t._v("。")]),t._v(" "),s("h2",{attrs:{id:"使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#使用"}},[t._v("#")]),t._v(" 使用")]),t._v(" "),s("h3",{attrs:{id:"解析文本并分词"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#解析文本并分词"}},[t._v("#")]),t._v(" 解析文本并分词")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//自动根据用户引入的分词库的jar来自动选择使用的引擎")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TokenizerEngine")]),t._v(" engine "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TokenizerUtil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createEngine")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//解析文本")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" text "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"这两个方法的区别在于返回值"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Result")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" engine"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//输出：这 两个 方法 的 区别 在于 返回 值")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" resultStr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CollUtil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("join")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Iterator")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Word")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("当你引入Ansj，会自动路由到Ansj的库去实现分词，引入HanLP则会路由到HanLP，依此类推。")]),t._v(" "),s("p",[t._v("也就是说，使用Hutool之后，无论你用任何一种分词库，代码不变。")]),t._v(" "),s("h3",{attrs:{id:"自定义模板引擎"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#自定义模板引擎"}},[t._v("#")]),t._v(" 自定义模板引擎")]),t._v(" "),s("p",[t._v("此处以HanLP为例：")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TokenizerEngine")]),t._v(" engine "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HanLPEngine")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//解析文本")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" text "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"这两个方法的区别在于返回值"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Result")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" engine"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//输出：这 两个 方法 的 区别 在于 返回 值")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" resultStr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CollUtil")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("join")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Iterator")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Word")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);